{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Food Vision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU\n",
    "\n",
    "Google Colab offers free GPUs (thank you Google), however, not all of them are compatiable with mixed precision training.\n",
    "\n",
    "Google Colab offers:\n",
    "* K80 (not compatible)\n",
    "* P100 (not compatible) \n",
    "* Tesla T4 (compatible)\n",
    "\n",
    "Knowing this, in order to use mixed precision training we need access to a Tesla T4 (from within Google Colab) or if we're using our own hardware, our GPU needs a score of 7.0+ (see here: https://developer.nvidia.com/cuda-gpus).\n",
    "\n",
    "ðŸ“– **Resource:** You can read more about the benefits of mixed precision training in the TensorFlow Mixed Precision documentation: https://www.tensorflow.org/guide/mixed_precision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce MX330 (UUID: GPU-77eebd61-350b-2f9c-b351-0acab8f44c51)\n"
     ]
    }
   ],
   "source": [
    "# If the following line doesn't output \"Tesla T4\", you can try getting access to\n",
    "# another GPU by going to Runtime -> Factory Reset Runtime -> \"Yes\" and then\n",
    "# re-running this cell.\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Since I don't have a good GPU for mixed precision, I had executed the code in Google Colab using the Tesla T4 GPU and had paste the output here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get helper functions\n",
    "helper.py file consists of many pre-written functions such as for graphs etc. which will be very useful in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import series of helper functions for the notebook\n",
    "from helper_functions import create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TensorFlow Datasets to Download Data\n",
    "\n",
    "If you want to get an overview of TensorFlow Datasets (TFDS), read the guide: https://www.tensorflow.org/datasets/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TensorFlow Datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** Some of the datasets contained within TensorFlow datasets are over 100GB+, meaning if you run the cell below (outside of Google Colab), you might be downloading 100GB+ to your computer or the computer that you're using. Beware as this could take a large amount of bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# List all available datasets\n",
    "datasets_list = tfds.list_builders() # get all available datasets in TFDS\n",
    "print(\"food101\" in datasets_list) # is our target dataset in the list of TFDS datasets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data (takes 5-6 minutes in Google Colab)\n",
    "(train_data, test_data), ds_info = tfds.load(name=\"food101\",\n",
    "                                             split=[\"train\", \"validation\"], # splits can be a little tricky, for more see: https://www.tensorflow.org/datasets/splits \n",
    "                                             shuffle_files=True,\n",
    "                                             as_supervised=True, # data gets returned in tuple format (data, label)\n",
    "                                             with_info=True) # for meta-data\n",
    "\n",
    "#OUTPUT:\n",
    "# Downloading and preparing dataset 4.65 GiB (download: 4.65 GiB, generated: Unknown size, total: 4.65 GiB) to /root/tensorflow_datasets/food101/2.0.0...\n",
    "# Dl Completed...: 100%\n",
    "# 1/1 [11:00<00:00, 343.23s/ url]\n",
    "# Dl Size...: 100%\n",
    "# 4764/4764 [11:00<00:00, 15.26 MiB/s]\n",
    "# Extraction completed...: 94%\n",
    "# 101008/101008 [11:00<00:00, 1083.67 file/s]\n",
    "# Dataset food101 downloaded and prepared to /root/tensorflow_datasets/food101/2.0.0. Subsequent calls will reuse this data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
